{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import torch\n",
    "from typing import Callable\n",
    "import os\n",
    "\n",
    "import nn_util\n",
    "# from nn_util import dist_and_proximity_loss, simple_dist_loss\n",
    "from main import determine_device\n",
    "\n",
    "device: torch.device = determine_device(1)\n",
    "\n",
    "\n",
    "# For saving to LaTeX\n",
    "# matplotlib.use(\"pgf\")\n",
    "# matplotlib.rcParams.update({\n",
    "#     \"pgf.texsystem\": \"pdflatex\",\n",
    "#     'font.family': 'serif',\n",
    "#     'text.usetex': True,\n",
    "#     'pgf.rcfonts': False,\n",
    "# })\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(loss_func:Callable, e:tuple[float,float], c:tuple[float,float], C:list[tuple[float,float]]) -> float:\n",
    "    predicted_embedding = torch.Tensor([e]).to(device)\n",
    "    target_labels: list[int] = [C.index(c)]\n",
    "    class_embeddings = torch.Tensor(C).to(device)\n",
    "\n",
    "    return loss_func(predicted_embedding, class_embeddings, target_labels, device)[0].item()\n",
    "\n",
    "# 𝑒 = The embedding outputted by the neural network\n",
    "# 𝑐  = The class embedding for the class of 𝑒\n",
    "# 𝐶  = The set of class embeddings\n",
    "def make_heatmap_moving_target_class(\n",
    "        x_min:int, x_max:int, y_min:int, y_max:int, resolution_upscale:float,\n",
    "        loss_func:Callable, target:tuple[float,float], all_classes:list[tuple[float,float]]\n",
    "        ) -> tuple[np.ndarray, tuple[int,int,int,int]]:\n",
    "    \n",
    "    heatmap = np.ndarray(shape=(\n",
    "        int(np.floor((x_max-x_min)*resolution_upscale)),\n",
    "        int(np.floor((y_max-y_min)*resolution_upscale)))\n",
    "    )\n",
    "\n",
    "    for x_i, y_i in np.ndindex(heatmap.shape):\n",
    "        x = x_i / resolution_upscale + x_min\n",
    "        y = y_i / resolution_upscale + y_min\n",
    "        heatmap[x_i, y_i] = get_loss(loss_func, target, (x,y), [(x,y)] + all_classes, )\n",
    "\n",
    "    return heatmap, (x_min, x_max, y_min, y_max)\n",
    "\n",
    "def make_heatmap_moving_embedding(\n",
    "        x_min:int, x_max:int, y_min:int, y_max:int, resolution_upscale:float,\n",
    "        loss_func:Callable, target:tuple[float,float], all_classes:list[tuple[float,float]]\n",
    "        ) -> tuple[np.ndarray, tuple[int,int,int,int]]:\n",
    "    \n",
    "    heatmap = np.ndarray(shape=(\n",
    "        int(np.floor((x_max-x_min)*resolution_upscale)),\n",
    "        int(np.floor((y_max-y_min)*resolution_upscale)))\n",
    "    )\n",
    "\n",
    "    for x_i, y_i in np.ndindex(heatmap.shape):\n",
    "        x = x_i / resolution_upscale + x_min\n",
    "        y = y_i / resolution_upscale + y_min\n",
    "        heatmap[x_i, y_i] = get_loss(loss_func, (x,y), target, [target] + all_classes, )\n",
    "\n",
    "    return heatmap, (x_min, x_max, y_min, y_max)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = -30\n",
    "x_max = 20\n",
    "y_min = -30\n",
    "y_max = 20\n",
    "\n",
    "resolution_upscale = 3\n",
    "\n",
    "e = (-7,-3)\n",
    "c = (-7,-3)\n",
    "all_classes = [(-6, 3),(-1,1),(4,7),(6,0),(4,-6)]\n",
    "\n",
    "def standardized_heatmap_moving_target(loss_func): \n",
    "    return make_heatmap_moving_target_class(x_min, x_max, y_min, y_max, resolution_upscale,\n",
    "                              loss_func, e, all_classes)\n",
    "\n",
    "def standardized_heatmap_moving_embedding(loss_func): \n",
    "    return make_heatmap_moving_embedding(x_min, x_max, y_min, y_max, resolution_upscale,\n",
    "                              loss_func, c, all_classes)\n",
    "\n",
    "def loss_heatmap_moving_target(loss_func, title=None): \n",
    "    heatmap, edges = standardized_heatmap_moving_target(loss_func)\n",
    "    \n",
    "    plt.clf()\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "        \n",
    "    plt.imshow(heatmap.T, extent=edges, origin='lower')\n",
    "    plt.scatter([e[0]], [e[1]], marker=\"$e$\")\n",
    "\n",
    "    cx = [c[0] for c in all_classes]\n",
    "    cy = [c[1] for c in all_classes]\n",
    "    plt.scatter(cx,cy, marker=\"$C$\")\n",
    "    # plt.show()\n",
    "    plt.savefig(\"loss_plots/\" + title)\n",
    "    # plt.savefig(\"loss_plots/\" + title + \".pgf\") # Requires a local installation of LaTeX\n",
    "\n",
    "def loss_heatmap_moving_embedding(loss_func, title=None): \n",
    "    heatmap, edges = standardized_heatmap_moving_embedding(loss_func)\n",
    "    \n",
    "    plt.clf()\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "        \n",
    "    plt.imshow(heatmap.T, extent=edges, origin='lower')\n",
    "    plt.scatter([c[0]], [c[1]], marker=\"$c$\")\n",
    "\n",
    "    cx = [c[0] for c in all_classes]\n",
    "    cy = [c[1] for c in all_classes]\n",
    "    plt.scatter(cx,cy, marker=\"$C$\")\n",
    "    # plt.show()\n",
    "    plt.savefig(\"loss_plots/\" + title)\n",
    "    # plt.savefig(\"loss_plots/\" + title + \".pgf\") # Requires a local installation of LaTeX\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_heatmap_moving_target(nn_util.simple_dist_loss, title=\"Simple Loss - Given e\")\n",
    "loss_heatmap_moving_embedding(nn_util.simple_dist_loss, title=\"Simple Loss - Given c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 1000\n",
    "loss_heatmap_moving_target(nn_util.dist_and_proximity_loss(r), title=\"Proximity Loss (r=\"+str(r)+\") - Given e\")\n",
    "loss_heatmap_moving_embedding(nn_util.dist_and_proximity_loss(r), title=\"Proximity Loss (r=\"+str(r)+\") - Given c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_heatmap_moving_target(nn_util.cone_loss_hyperparam(), title=\"Cone Loss - Given e\")\n",
    "loss_heatmap_moving_embedding(nn_util.cone_loss_hyperparam(), title=\"Cone Loss - Given c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_heatmap_moving_target(nn_util.comparison_dist_loss, title=\"Comparison Loss - Given e\")\n",
    "loss_heatmap_moving_embedding(nn_util.comparison_dist_loss, title=\"Comparison Loss - Given c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_heatmap_moving_target(nn_util.cosine_loss, title=\"Cosine Loss - Given e\")\n",
    "loss_heatmap_moving_embedding(nn_util.cosine_loss, title=\"Cosine Loss - Given c\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
